# createpivot.py

**Description:**
The `createpivot.py` script is an essential component in the preprocessing pipeline for predicting pollution levels based on environmental and vehicle-related data. The script leverages the pandas library to load and manipulate a dataset stored in the 'Air_Quality.csv' file. The primary objective is to filter and merge relevant information to create a pivot table, a structured representation of data for subsequent machine learning tasks.

**Code Overview:**
1. **Loading Data:** The script begins by loading the CSV file ('Air_Quality.csv') into a pandas DataFrame.

2. **Defining Relevant Indicators:** A list of relevant indicators, including vehicle-related metrics and boiler emissions, is specified.

3. **Creating Vehicle Data and Pollution Data DataFrames:** The dataset is filtered to create separate DataFrames for vehicle-related data (for the years 2005 and 2016) and pollution data (for the years 2005 and 2016). These DataFrames are then aggregated based on specific criteria.

4. **Merging DataFrames:** The vehicle and pollution DataFrames are merged into a comprehensive DataFrame named 'merged_data.' The merge operation is based on common columns such as 'Geo Place Name' and 'Time Period.'

5. **Creating Pivot Table:** The merged data is transformed into a pivot table named 'test_pivot.' This table is structured with pollution-related features as indices, vehicle-related features as columns, and 'Data Value_vehicle' as values. The resulting pivot table is saved as 'pivot.csv.'

---

# model2.py

**Description:**
The `model2.py` script serves as the second phase of the pollution prediction project, building upon the preprocessed data generated by `createpivot.py`. This script involves the implementation of a neural network model using TensorFlow and Keras for regression-based predictions. Additionally, it includes the integration of SHAP (SHapley Additive exPlanations) for interpretability.

**Code Overview:**
1. **Loading Preprocessed Data:** The script begins by loading the preprocessed data from 'pivot.csv' into a pandas DataFrame named 'new_df.'

2. **Data Preprocessing:** Several preprocessing steps are performed, including mapping geographical locations, handling missing values, and converting categorical data to numeric format.

3. **Neural Network Model:** A sequential neural network model is constructed using Keras. The model architecture consists of input and output layers, as well as multiple hidden layers with Batch Normalization and Leaky ReLU activation functions. The model is trained on the preprocessed data with mean squared error as the loss function.

4. **Model Evaluation:** The trained model is evaluated using mean squared error and R-squared metrics. Additionally, the script generates a plot comparing actual and predicted values.

5. **SHAP Analysis:** The script utilizes the SHAP library to perform model interpretation. SHAP values are calculated and visualized through summary plots, bar plots, and waterfall plots to provide insights into feature contributions.

**Note:**
The output of `createpivot.py` (pivot.csv) serves as the input for `model2.py`, emphasizing the workflow continuity from data preprocessing to model development and interpretation.

---
